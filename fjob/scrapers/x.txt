PRACUJPL


import logging
from typing import Dict, Optional, Tuple, List
from bs4 import BeautifulSoup

import requests
import re

from ..scraper import (
    Scraper,
    ParsedOffer,
    ParsedWebsite,
    ParsedSalary,
    ParsedLocalization,
    ParsedExperienceLevel,
)

logging.basicConfig(
    filename="../logs.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


class PracujPLIT(Scraper):
    """
    A scraper for the Pracuj.pl jobs board.
    """

    def __init__(self, url: str = "https://it.pracuj.pl/praca") -> None:
        super().__init__(url)
        self.max_page_number = None

    def fetch_data(self) -> Optional[str]:
        try:
            response = requests.get(self.url)
            response.raise_for_status()
            return response.text
        except Exception as e:
            logging.error(f"Error occurred: {e}")
        return None

    @staticmethod
    def get_max_page_number(data: str) -> Optional[int]:
        if not data:
            return None

        soup = BeautifulSoup(data, "html.parser")
        max_page_element = soup.find(
            "span", {"data-test": "top-pagination-max-page-number"}
        )
        if max_page_element:
            return int(max_page_element.text)
        return None

    def run(self) -> None:
        data = self.fetch_data()
        if data:
            self.max_page_number = self.get_max_page_number(data)

        if self.max_page_number:
            for page in range(1, self.max_page_number + 1):
                self.url = f"https://it.pracuj.pl/praca?pn={page}"
                data = self.fetch_data()
                if data:
                    parsed_data = self.parse_offer(data)
                    print(parsed_data)
                    # self.save_data(parsed_data)
                else:
                    logging.info("No data received")

    @staticmethod
    def get_experience_level(data: List[str]) -> Optional[str]:
        if not data:
            return None

        if "Mid" in data:
            return "Mid"
        if "Senior" in data:
            return "Senior"
        if "Junior" in data:
            return "Junior"
        if "Praktykant" in data:
            return "Praktykant"
        if "Stażysta" in data:
            return "Stażysta"

    @staticmethod
    def is_remote(data: List[str]) -> bool:
        if "Praca zdalna" in data:
            return True
        return False

    @staticmethod
    def is_hybrid(data: List[str]) -> bool:
        if "Praca hybrydowa" in data:
            return True
        return False

    @staticmethod
    def get_contract_type(data: List[str]) -> List[Optional[str]]:
        result = []
        if not data:
            return []

        if "Umowa o pracę" in data:
            result.append("Umowa o pracę")
        elif "Umowa zlecenie" in data:
            result.append("Umowa zlecenie")
        elif "Umowa o dzieło" in data:
            result.append("Umowa o dzieło")
        elif "Kontrakt B2B" in data:
            result.append("Kontrakt B2B")
        elif "Umowa o zastępstwo" in data:
            result.append("Umowa o zastępstwo")
        elif "Umowa agencyjna" in data:
            result.append("Umowa agencyjna")
        elif "Umowa o pracę tymczasową" in data:
            result.append("Umowa o pracę tymczasową")
        elif "Umowa o staż / praktyki" in data:
            result.append("Umowa o staż / praktyki")

        return result

    @staticmethod
    def parse_localization(text: str) -> Optional[str]:
        result = None
        if not text:
            return None

        if "localizacji":
            result = None

        split_data = text.split()
        if len(split_data) == 1:
            result = text
        else:
            result = split_data[0]

        return result

    def parse_offer(self, data: str) -> List[ParsedOffer]:
        parsed_data = []

        soup = BeautifulSoup(data, "html.parser")
        offers_section = soup.find("div", {"data-test": "section-offers"})
        if offers_section:
            offers = offers_section.find_all(
                "div", class_="listing-it_bp811tr listing-it_po9665q"
            )

            if offers:
                for offer in offers:
                    title = None
                    additional_data = None
                    url = None
                    parsed_localization = None
                    skills_list = None
                    company_logo = None
                    company_name = None

                    title_element = offer.find(
                        "a", class_="listing-it_o1bdr2ew listing-it_n194fgoq"
                    )
                    company_element = offer.find("img", class_="listing-it_ia9ocxs")
                    skills_container = offer.find(
                        "div", {"data-test": "technologies-list"}
                    )
                    additional_data_container = offer.find(
                        "ul", class_="listing-it_b1ef77ng"
                    )
                    localization_element = offer.find(
                        "h5", {"date-test": "text-region"}
                    )

                    if localization_element:
                        localization_text = localization_element.text
                        parsed_localization = self.parse_localization(localization_text)

                    if additional_data_container:
                        additional_data_list = additional_data_container.find_all("li")
                        if additional_data_list:
                            additional_data = [
                                data.text for data in additional_data_list
                            ]

                    if skills_container:
                        skills = skills_container.find_all(
                            "span", {"data-test": "technologies-item"}
                        )
                        if skills:
                            skills_list = [skill.text for skill in skills]

                    if company_element:
                        company_logo = company_element.get("src")
                        company_name = company_element.get("alt")
                    if title_element:
                        url = title_element.get("href")
                        title = title_element.text

                    salaries = []
                    if additional_data:
                        contracts = self.get_contract_type(additional_data)
                        for contract in contracts:
                            salaries.append(Salary(contract_type=contract))

                    parsed_data.append(
                        ParsedOffer(
                            title=title if title else None,
                            url=url if url else None,
                            remote=self.is_remote(additional_data)
                            if additional_data
                            else None,
                            hybrid=self.is_hybrid(additional_data)
                            if additional_data
                            else None,
                            country="PL",
                            additional_data=additional_data
                            if additional_data
                            else None,
                            salary=salaries if salaries else None,
                            city=parsed_localization if parsed_localization else None,
                            skills=skills_list if skills_list else None,
                            company_name=company_name if company_name else None,
                            company_logo=company_logo if company_logo else None,
                            experience_level=self.get_experience_level(additional_data)
                            if additional_data
                            else None,
                        )
                    )

        return parsed_data




@shared_task()
def pracujpl_task() -> List[Optional[Dict[str, Any]]]:
    try:
        scraper = PracujPLIT()
        scraper.run()
    except Exception as e:
        logging.error(f"Error occurred during scraping: {e}")
        return []



THEPROTOCOL


import httpx
from bs4 import BeautifulSoup
from ..scraper import (
    Scraper,
    ParsedOffer,
    ParsedLocalization,
    ParsedSalary,
    ParsedWebsite,
    ParsedExperienceLevel,
)
from typing import List, Dict, Any, Optional
import logging


logging.basicConfig(
    filename="../logs.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
)


BASE_URL = "https://theprotocol.it/?pageNumber="
MAX_PAGE_NUM = 54


class TheProtocol(Scraper):
    def __init__(self):
        super().__init__(url=BASE_URL)
        self.page_num = 1
        self.data = []

    def fetch_data(self) -> Optional[str]:
        try:
            response = httpx.get(f"{BASE_URL}{self.page_num}")
            return response.text
        except Exception as e:
            logging.error(f"Error occurred during fetching data: {e}")
            return None

    def parse_data(self, response: str) -> None:
        try:
            soup = BeautifulSoup(response, "html.parser")
            job_cards = soup.find_all("a", class_="anchorClass_a6of9et")
        except Exception as e:
            logging.error(f"Error occurred during extracting data: {e}")
            return None

        try:
            for card in job_cards:
                offer_data = {}

                title = card.find("h2", class_="titleText_t1280ha4")
                url = card.get("href")
                company_logo = card.find("img")
                details = card.find_all("div", class_="rootClass_rpqnjlt")
                skill_divs = card.find_all(
                    "div", {"data-test": "chip-expectedTechnology"}
                )
                skills = []
                if skill_divs:
                    for div in skill_divs:
                        spans = div.find_all("span", class_="Label_l1fs6hs4")
                        for span in spans:
                            skills.append(span.text)
                localization = card.find("div", {"data-test": "text-workplaces"})
                d = {}
                for idx, detail in enumerate(details):
                    if idx == 0:
                        d["company_name"] = detail

                    if idx == 1:
                        d["work_mode"] = detail
                if title:
                    offer_data["title"] = title.text
                if company_logo:
                    offer_data["company_logo"] = company_logo["src"]
                if d.get("company_name", None):
                    offer_data["company_name"] = d["company_name"].text
                if d.get("work_mode", None):
                    offer_data["work_mode"] = d["work_mode"].text
                if skills:
                    offer_data["skills"] = skills
                if localization:
                    offer_data["localization"] = localization.text
                if url:
                    offer_data["url"] = url
                self.data.append(offer_data)
        except Exception as e:
            logging.error(f"Error occurred during parsing data: {e}")
            return None

    @staticmethod
    def get_experience_level(title: str) -> List[Optional[str]]:
        result = []
        skills = title.lower()

        if "junior" in skills or "młodszy" in skills:
            result.append("Junior")
        if "intern" in skills or "internship" in skills or "stażysta" in skills:
            result.append("Internship")
        if "senior" in skills or "starszy" in skills or "expert" in skills:
            result.append("Senior")
        if "dyrektor" in skills or "direktor" in skills:
            result.append("Director")
        if "manager" in skills or "menedżer" in skills:
            result.append("Manager")

        return result

    @staticmethod
    def is_remote(title: str) -> bool:
        title = title.lower()
        if "remote" in title or "zdalny" in title:
            return True
        return False

    @staticmethod
    def is_hybrid(title: str) -> bool:
        if "hybrid" in title.lower() or "hybryd" in title.lower():
            return True
        else:
            return False

    def parse_offer(self, data: List[Dict[str, Any]]) -> List[Optional[ParsedOffer]]:
        parsed_offers = []

        website = ParsedWebsite(name="theprotocol.it", url="https://theprotocol.it/")

        try:
            for offer in data:
                experience_levels = self.get_experience_level(offer.get("title", None))
                is_remote = self.is_remote(offer.get("title", None))
                is_hybrid = self.is_hybrid(offer.get("title", None))

                exp_levels = []
                if experience_levels:
                    for exp in experience_levels:
                        exp_levels.append(ParsedExperienceLevel(name=exp))

                localization = ParsedLocalization(
                    country="Poland", city=offer.get("localization", None)
                )

                parsed_offers.append(
                    ParsedOffer(
                        title=offer.get("title", None),
                        company_name=offer.get("company_name", None),
                        company_logo=offer.get("company_logo", None),
                        skills=offer.get("skills", None),
                        url=f"{'https://theprotocol.it/'}{offer.get('url', None)}",
                        is_hybrid=is_hybrid,
                        is_remote=is_remote,
                        experience_level=exp_levels,
                        website=website,
                        localizations=[localization],
                    )
                )
        except Exception as e:
            logging.error(f"Error occurred during parsing offer: {e}")
            return []

        return parsed_offers

    def pipeline(self) -> List[Optional[ParsedOffer]]:
        try:
            for i in range(1, MAX_PAGE_NUM):
                response = self.fetch_data()
                self.parse_data(response)
                self.page_num += 1

            logging.info(f"Parsed {len(self.data)} offers from theprotocol.it")
            return self.parse_offer(self.data)
        except Exception as e:
            logging.error(f"Error occurred during pipeline: {e}")
            return []



def theprotocol_task() -> None:
    try:
        theprotocol_scraper = TheProtocol()
        data = theprotocol_scraper.pipeline()
        theprotocol_scraper.save_data(data)

    except Exception as e:
        logging.error(f"Error occurred during scraping: {e}")
